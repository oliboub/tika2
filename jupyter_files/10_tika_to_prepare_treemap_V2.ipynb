{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8816629a-d436-4802-8ac0-a092a2183f5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare file source for a treemap display based on a directory of files already preparfed thrue ika step1\n",
    "- Files directory in category\n",
    "\n",
    "Creation of files:<br>\n",
    " |name |description|\n",
    " |---|---|\n",
    " | **category__total__wordscount.csv** | one file by filename containing all metadata and qtt of words found inthis file|\n",
    " | **category__wordcounts__with_files.csv** | one file by filename containing all metadata and qtt of words found inthis file|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08457f-13e2-4950-b02a-4f5040745ab7",
   "metadata": {},
   "source": [
    "# This program intends:\n",
    "## Step 1\n",
    "- To get multiple files in pandas dataframe wrods, count, butr link to a category name\n",
    "- To concatenate all of these datframe in one dataframe\n",
    "- To prepare a treemap\n",
    "- To generate a file for the treemap\n",
    "<br>\n",
    "## Step2\n",
    "- To create treemap\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d19d533-24bf-4c40-8d60-0643f6e09dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tika import parser\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import signal\n",
    "import glob\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c31f543-2afa-4a58-a4ca-77fc7dacc6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import global_variables as g\n",
    "g.init()\n",
    "\n",
    "category=g.category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878db5a-bc49-4a6e-9313-c2727b81a3db",
   "metadata": {},
   "source": [
    "## Prepare list of file to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e28953-29b7-493a-b4b2-d3f5720be5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23  fichier(s) à traiter\n",
      " ['doc-engineering__test1.png__wordscount.csv', 'doc-engineering__A330 -2.jpeg__wordscount.csv', 'doc-engineering__test6.odt__wordscount.csv', 'doc-engineering__test10.pdf__wordscount.csv', 'doc-engineering__A330.jpeg__wordscount.csv', 'doc-engineering__test9.tiff__wordscount.csv', 'doc-engineering__test1.pdf__wordscount.csv', 'doc-engineering__test10.tiff__wordscount.csv', 'doc-engineering__test7.pdf__wordscount.csv', 'doc-engineering__test13.odt__wordscount.csv', 'doc-engineering__test5.odt__wordscount.csv', 'doc-engineering__test2.jpg__wordscount.csv', 'doc-engineering__a3802pdf.pdf__wordscount.csv', 'doc-engineering__test7.odt__wordscount.csv', 'doc-engineering__test11.docx__wordscount.csv', 'doc-engineering__A330 -3.jpeg__wordscount.csv', 'doc-engineering__test51.odt__wordscount.csv', 'doc-engineering__test3.jpg__wordscount.csv', 'doc-engineering__test1.odt__wordscount.csv', 'doc-engineering__a3802pdf.tiff__wordscount.csv', 'doc-engineering__test14.odt__wordscount.csv', 'doc-engineering__test12.odt__wordscount.csv', 'doc-engineering__a380.odt__wordscount.csv']\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    " \n",
    "#parallelism =  4 \n",
    "\n",
    "if g.DEBUG_OL >= 2:\n",
    "    print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "#print(\"date and time =\", dt_string)\n",
    "\n",
    "#category=\"doc-engineering\"\n",
    "#category=\"doc-consoles\"\n",
    "#category=\"doc-electro\"\n",
    "#category=\"doc-photo\"\n",
    "#category=\"doc-airbus\"\n",
    "#category=\"doc-tests\"\n",
    "#dirlist = os.listdir(category+'_*.csv')\n",
    "\n",
    "dirlist = [f for f in glob.glob(category+'_*.csv')]\n",
    "my_output_file=category+'__total__wordcounts.csv'\n",
    "my_full_output_file=category+'__wordcounts__with_files.csv'\n",
    "\n",
    "my_file_list = [s for s in dirlist if \"__wordscount.csv\" in s]\n",
    "\n",
    "#print(dirlist)\n",
    "#for i in range(len(dirlist)):\n",
    "#    dirlist[i]=''.join(dirlist[i].split())\n",
    "    \n",
    "if g.DEBUG_OL >= 1:\n",
    "    print(len(my_file_list),' fichier(s) à traiter\\n', my_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e17b0-d717-4852-8e5c-76d5b76aa499",
   "metadata": {},
   "source": [
    "## load pandas dataframe file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7b3b55-c620-44a4-97d7-071c23aea43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes = []\n",
    "full_list_with_files = []\n",
    "\n",
    "for filename in my_file_list:\n",
    "\n",
    "    start_str = filename.find('__')\n",
    "    end_str=filename.find('__',start_str+1)\n",
    "    my_file=filename[start_str+2:end_str]\n",
    "    if g.DEBUG_OL >= 2:\n",
    "        print(start_str+1,end_str,my_file)\n",
    "    \n",
    "    \n",
    "    full_current_dataframe=pd.read_csv(filename,encoding='utf-8')\n",
    "    full_current_dataframe['file']=my_file\n",
    "    full_list_with_files.append(full_current_dataframe)\n",
    "    my_list_array = pd.concat(full_list_with_files)\n",
    "    if g.DEBUG_OL >= 2:\n",
    "        print(my_list_array)\n",
    "        display(full_current_dataframe)\n",
    "    \n",
    "    current_dataframe=pd.read_csv(filename)\n",
    "    list_of_dataframes.append(current_dataframe)\n",
    "my_list_array.to_csv(my_full_output_file,header=True,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdde4b30-7a11-4a74-b978-d187199ce378",
   "metadata": {},
   "outputs": [],
   "source": [
    "if g.DEBUG_OL >= 2:\n",
    "    display(list_of_dataframes)\n",
    "my_loaded_array = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5442396-25c6-4886-ad29-1a2c1fc8451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if g.DEBUG_OL >= 2:\n",
    "    print(my_loaded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b370853-4e24-480a-9bb4-7b8ca615e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output_array=my_loaded_array.groupby(['words']).sum().reset_index()\n",
    "my_output_array.sort_values('count', ascending=False, inplace=True)\n",
    "if g.DEBUG_OL >= 2:\n",
    "        display(my_output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2f7a6-4611-4ecb-9c40-a2b00de5ca32",
   "metadata": {},
   "source": [
    "## save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce530b8f-b9f7-485b-ab3e-6b9965b8a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output_array.to_csv(my_output_file,header=True,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4aa7091-ac96-4141-8bab-5f5efa97f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process terminé.\n"
     ]
    }
   ],
   "source": [
    "print('Process terminé.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
